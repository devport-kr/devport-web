export type Category = 'AI_LLM' | 'DEVOPS_SRE' | 'BACKEND' | 'INFRA_CLOUD' | 'OTHER';

export type ItemType = 'REPO' | 'BLOG' | 'DISCUSSION';

export type Source = 'github' | 'hackernews' | 'reddit' | 'medium' | 'devto' | 'hashnode';

export interface Article {
  id: string;
  itemType: ItemType;
  source: Source;
  category: Category;
  summaryKoTitle: string;
  summaryKoBody?: string;
  titleEn: string;
  url: string;
  score: number;
  tags: string[];
  createdAtSource: string;
  metadata?: {
    stars?: number;
    comments?: number;
    upvotes?: number;
    readTime?: string;
    language?: string;
  };
}

export const categoryConfig: Record<Category, { label: string; color: string }> = {
  AI_LLM: { label: 'AI/LLM', color: 'bg-purple-600' },
  DEVOPS_SRE: { label: 'DevOps/SRE', color: 'bg-cyan-600' },
  BACKEND: { label: 'Backend', color: 'bg-green-600' },
  INFRA_CLOUD: { label: 'Infra/Cloud', color: 'bg-amber-600' },
  OTHER: { label: 'Other', color: 'bg-gray-600' },
};

export const sourceConfig: Record<Source, { label: string; icon: string }> = {
  github: { label: 'GitHub', icon: 'ğŸ“¦' },
  hackernews: { label: 'Hacker News', icon: 'ğŸ“°' },
  reddit: { label: 'Reddit', icon: 'ğŸ’¬' },
  medium: { label: 'Medium', icon: 'ğŸ“' },
  devto: { label: 'Dev.to', icon: 'ğŸ“' },
  hashnode: { label: 'Hashnode', icon: 'ğŸ“' },
};

// LLM Leaderboard Types
export type BenchmarkType = 'AGENTIC_CODING' | 'REASONING' | 'MATH' | 'VISUAL' | 'MULTILINGUAL';

export interface LLMModel {
  id: string;
  name: string;
  provider: string;
  score: number;
  contextWindow?: string;
  pricing?: string;
}

export const benchmarkConfig: Record<BenchmarkType, {
  label: string;
  labelKo: string;
  description: string;
  descriptionKo: string;
  icon: string;
}> = {
  AGENTIC_CODING: {
    label: 'Agentic Coding',
    labelKo: 'ì—ì´ì „í‹± ì½”ë”©',
    description: 'Data from the SWE Benchmark that evaluates if LLMs can resolve GitHub Issues. It measures agentic reasoning.',
    descriptionKo: 'LLMì´ GitHub ì´ìŠˆë¥¼ í•´ê²°í•  ìˆ˜ ìˆëŠ”ì§€ í‰ê°€í•˜ëŠ” SWE ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…ë‹ˆë‹¤. ì—ì´ì „í‹± ì¶”ë¡  ëŠ¥ë ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤.',
    icon: 'ğŸ’»'
  },
  REASONING: {
    label: 'Reasoning',
    labelKo: 'ì¶”ë¡  ëŠ¥ë ¥',
    description: 'Data from the GPQA Diamond, a very complex benchmark that evaluates quality and reliability across biology, physics, and chemistry.',
    descriptionKo: 'ìƒë¬¼í•™, ë¬¼ë¦¬í•™, í™”í•™ ë¶„ì•¼ì˜ í’ˆì§ˆê³¼ ì‹ ë¢°ì„±ì„ í‰ê°€í•˜ëŠ” ë§¤ìš° ë³µì¡í•œ ë²¤ì¹˜ë§ˆí¬ì¸ GPQA ë‹¤ì´ì•„ëª¬ë“œì˜ ë°ì´í„°ì…ë‹ˆë‹¤.',
    icon: 'ğŸ§ '
  },
  MATH: {
    label: 'High School Math',
    labelKo: 'ê³ ê¸‰ ìˆ˜í•™',
    description: 'Data from the AIME 2024, a competitive high school math benchmark.',
    descriptionKo: 'ê²½ìŸì ì¸ ê³ ë“±í•™êµ ìˆ˜í•™ ë²¤ì¹˜ë§ˆí¬ì¸ AIME 2024ì˜ ë°ì´í„°ì…ë‹ˆë‹¤.',
    icon: 'ğŸ“'
  },
  VISUAL: {
    label: 'Visual Reasoning',
    labelKo: 'ì‹œê° ì¶”ë¡ ',
    description: 'ARC-AGI-2 which challenges systems to demonstrate both high adaptability and high efficiency.',
    descriptionKo: 'ì‹œìŠ¤í…œì´ ë†’ì€ ì ì‘ì„±ê³¼ íš¨ìœ¨ì„±ì„ ëª¨ë‘ ì…ì¦í•˜ë„ë¡ ìš”êµ¬í•˜ëŠ” ARC-AGI-2 ë²¤ì¹˜ë§ˆí¬ì…ë‹ˆë‹¤.',
    icon: 'ğŸ‘ï¸'
  },
  MULTILINGUAL: {
    label: 'Multilingual',
    labelKo: 'ë‹¤êµ­ì–´ ì²˜ë¦¬',
    description: 'MMMLU which covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science in 14 languages.',
    descriptionKo: 'ë²•í•™, ë¬¼ë¦¬í•™, ì—­ì‚¬, ì»´í“¨í„° ê³¼í•™ê³¼ ê°™ì€ ì „ë¬¸ ê³¼ëª©ë¶€í„° ì´ˆë“± ìˆ˜ì¤€ì˜ ì§€ì‹ê¹Œì§€ 57ê°œ ì¹´í…Œê³ ë¦¬ì˜ ê´‘ë²”ìœ„í•œ ì£¼ì œë¥¼ 14ê°œ ì–¸ì–´ë¡œ ë‹¤ë£¨ëŠ” MMMLU ë²¤ì¹˜ë§ˆí¬ì…ë‹ˆë‹¤.',
    icon: 'ğŸŒ'
  }
};

// Centralized icon configuration for easy replacement with custom icons
export const icons = {
  // Section icons
  githubLeaderboard: 'ğŸ†',
  llmLeaderboard: 'ğŸ¤–',
  trendingBlog: 'ğŸ“š',

  // Metadata icons
  time: 'ğŸ•',
  star: 'â­',
  comment: 'ğŸ’¬',
  upvote: 'â¬†ï¸',
  readTime: 'ğŸ“–',
  language: 'ğŸŒ',
} as const;
